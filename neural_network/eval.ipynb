{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized with 175 files. Zero-sample probability: 0.00\n",
      "Losses on 48000 Hz, trained with 48000 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 6/6 [00:03<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESR value: 0.0019671963527798653\n",
      "ESR_dB value: -27.06152289458973\n",
      "MR STFT value: 0.2501034736633301\n",
      "Dataset initialized with 175 files. Zero-sample probability: 0.00\n",
      "Losses on 44100 Hz, trained with 48000 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 6/6 [00:02<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESR value: 0.002255569212138653\n",
      "ESR_dB value: -26.467438420361347\n",
      "MR STFT value: 0.24015912413597107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Calculate loss on test set and change sampling rate\"\"\"\n",
    "import torch\n",
    "from model.mamba import Mamba\n",
    "from config import ModelParams, HyperParams\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import AudioSegmentDataset, eval\n",
    "\n",
    "device=\"cuda\"\n",
    "trained_sr = 48000\n",
    "\n",
    "model = Mamba(ModelParams).to(device)\n",
    "checkpoint = torch.load(f\"results/S5_mamba_model_{HyperParams.name}.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "loader = DataLoader(AudioSegmentDataset('dataset/test', sr=str(trained_sr), p_zero=0.0), batch_size=HyperParams.batch_size, shuffle=True)\n",
    "print(f\"Losses on {trained_sr} Hz, trained with {trained_sr} Hz\")\n",
    "eval(model, loader, ModelParams, HyperParams, device)\n",
    "\n",
    "sr = 44100\n",
    "model.change_scale(trained_sr/sr)\n",
    "loader = DataLoader(AudioSegmentDataset('dataset/test', sr=str(sr), p_zero=0.0), batch_size=HyperParams.batch_size, shuffle=True)\n",
    "print(f\"Losses on {sr} Hz, trained with {trained_sr} Hz\")\n",
    "eval(model, loader, ModelParams, HyperParams, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8. Sample Output (first 8 timesteps, first batch, can compare to C++ implementation):\n",
      "-------------------------\n",
      "Timestep   Parallel       \n",
      "-------------------------\n",
      "0          0.000072       \n",
      "1          0.011912       \n",
      "2          0.030952       \n",
      "3          0.056277       \n",
      "4          0.062342       \n",
      "5          0.054146       \n",
      "6          0.023015       \n",
      "7          -0.008738      \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model.mamba import Mamba\n",
    "from config import HyperParams, ModelParams\n",
    "from utils import init_hidden\n",
    "\n",
    "device = \"cpu\"\n",
    "sr = 44100\n",
    "model = Mamba(ModelParams)\n",
    "mamba_weights_path = f\"results/S5_mamba_model_{HyperParams.name}.pth\"\n",
    "model.load_state_dict(torch.load(mamba_weights_path, map_location=device))\n",
    "\n",
    "# Prepare inputs\n",
    "batch_size = 2\n",
    "N = 8\n",
    "#x = torch.randn(batch_size, N, 1, dtype=torch.float32)\n",
    "#c = torch.randn(batch_size, ModelParams.c_dim, dtype=torch.float32)\n",
    "x = torch.tensor([[0.0000000000, 0.3535531759, 0.5000000000, 0.3535540700, 0.0000012676, -0.3535522819, -0.5000000000, -0.3535549641],\n",
    "                  [0.5000000000, 0.3535558581, 0.0000038028, -0.3535504639, -0.5000000000, -0.3535567522, -0.0000050704, 0.3535495698]], dtype=torch.float32).unsqueeze(-1)\n",
    "c = torch.tensor([[0.8, -0.6], [0.8, -0.6]], dtype=torch.float32)\n",
    "c = c.unsqueeze(1).expand(-1, N, -1)\n",
    "h1, h2 = init_hidden(ModelParams.n_layers, batch_size, ModelParams.ssm_size, device)\n",
    "step_rescale = 48000 / sr\n",
    "model.change_scale(step_rescale)\n",
    "\n",
    "with torch.no_grad():\n",
    "    h1, h2 = init_hidden(ModelParams.n_layers, batch_size, ModelParams.ssm_size, device)\n",
    "    y, (h1, h2) = model(x, (h1, h2), c)\n",
    "\n",
    "print(f\"\\n8. Sample Output (first 8 timesteps, first batch, can compare to C++ implementation):\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"{'Timestep':<10} {'Parallel':<15}\")\n",
    "print(\"-\" * 25)\n",
    "for i in range(min(8, N)):\n",
    "    p = y[0, i, 0].item()\n",
    "    print(f\"{i:<10} {p:<15.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved as model_weights.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get model weights\"\"\"\n",
    "import torch\n",
    "from model2json import model_2_json\n",
    "from model.mamba import Mamba\n",
    "from config import ModelParams, HyperParams\n",
    "\n",
    "model = Mamba(ModelParams)\n",
    "model.load_state_dict(torch.load(f\"results/S5_mamba_model_{HyperParams.name}.pth\", map_location='cpu'))\n",
    "model_2_json(model)\n",
    "print(\"Model weights saved as model_weights.json\") # run \"xxd -i model_weights.json > model_weights.h\" to embed the json file in the plugin project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
